{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Getting Started with DTI Prediction\n",
    "\n",
    "This notebook demonstrates how to use the multi-modal DTI prediction framework for drug-target interaction prediction."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "from models import DrugGNN, ProteinPLM, TDAEncoder, FusionAttention, EvidentialHead\n",
    "from data import DTIDataset, ColdStartSplit\n",
    "from data.preprocessing import DrugPreprocessor, ProteinPreprocessor, TDAPreprocessor\n",
    "\n",
    "print(\"PyTorch version:\", torch.__version__)\n",
    "print(\"Device:\", \"cuda\" if torch.cuda.is_available() else \"cpu\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Load Dataset\n",
    "\n",
    "Let's load the Davis dataset and explore its structure."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load Davis dataset\n",
    "dataset = DTIDataset(\n",
    "    root='../data',\n",
    "    dataset_name='davis',\n",
    "    split='train'\n",
    ")\n",
    "\n",
    "print(f\"Dataset size: {len(dataset)}\")\n",
    "print(f\"Number of unique drugs: {len(set(dataset.data['drugs']))}\")\n",
    "print(f\"Number of unique proteins: {len(set(dataset.data['proteins']))}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Preprocess Data\n",
    "\n",
    "Convert drug SMILES to molecular graphs and protein sequences to embeddings."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize preprocessors\n",
    "drug_preprocessor = DrugPreprocessor()\n",
    "protein_preprocessor = ProteinPreprocessor()\n",
    "tda_preprocessor = TDAPreprocessor()\n",
    "\n",
    "# Example: Process a drug molecule\n",
    "example_smiles = \"CC(C)Cc1ccc(cc1)C(C)C(O)=O\"  # Ibuprofen\n",
    "drug_graph = drug_preprocessor.smiles_to_graph(example_smiles)\n",
    "\n",
    "print(\"Drug graph features:\")\n",
    "print(f\"  Nodes: {drug_graph['num_nodes']}\")\n",
    "print(f\"  Node features shape: {drug_graph['node_features'].shape}\")\n",
    "print(f\"  Edges: {drug_graph['edge_index'].shape[1]}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Initialize Models\n",
    "\n",
    "Create instances of each model component."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Model parameters\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "# Initialize encoders\n",
    "drug_gnn = DrugGNN(\n",
    "    in_features=78,\n",
    "    hidden_dim=256,\n",
    "    out_dim=256,\n",
    "    num_layers=3\n",
    ").to(device)\n",
    "\n",
    "protein_plm = ProteinPLM(\n",
    "    embedding_dim=1280,\n",
    "    out_dim=256\n",
    ").to(device)\n",
    "\n",
    "tda_encoder = TDAEncoder(\n",
    "    input_dim=100,\n",
    "    out_dim=256\n",
    ").to(device)\n",
    "\n",
    "# Fusion and prediction\n",
    "fusion = FusionAttention(\n",
    "    drug_dim=256,\n",
    "    protein_dim=256,\n",
    "    tda_dim=256,\n",
    "    hidden_dim=512\n",
    ").to(device)\n",
    "\n",
    "prediction_head = EvidentialHead(\n",
    "    in_dim=512,\n",
    "    hidden_dim=256\n",
    ").to(device)\n",
    "\n",
    "print(\"Models initialized successfully!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Cold-Start Splits\n",
    "\n",
    "Generate different cold-start evaluation scenarios."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create cold-drug split\n",
    "cold_drug_splitter = ColdStartSplit(\n",
    "    dataset,\n",
    "    split_type='cold_drug',\n",
    "    test_ratio=0.2,\n",
    "    val_ratio=0.1\n",
    ")\n",
    "\n",
    "split_info = cold_drug_splitter.generate_split()\n",
    "\n",
    "print(\"Cold Drug Split:\")\n",
    "print(f\"  Train samples: {len(split_info['train'])}\")\n",
    "print(f\"  Val samples: {len(split_info['val'])}\")\n",
    "print(f\"  Test samples: {len(split_info['test'])}\")\n",
    "print(f\"  Test drugs: {len(split_info.get('test_drugs', []))}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Visualization\n",
    "\n",
    "Visualize model predictions and uncertainties."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Placeholder for visualization\n",
    "# In practice, you would load trained model and make predictions\n",
    "\n",
    "fig, axes = plt.subplots(1, 2, figsize=(12, 5))\n",
    "\n",
    "# Simulated data for demonstration\n",
    "y_true = np.random.randn(100) * 2 + 7\n",
    "y_pred = y_true + np.random.randn(100) * 0.5\n",
    "uncertainty = np.random.rand(100) * 2\n",
    "\n",
    "# Scatter plot of predictions vs true values\n",
    "axes[0].scatter(y_true, y_pred, alpha=0.6)\n",
    "axes[0].plot([5, 10], [5, 10], 'r--', label='Perfect prediction')\n",
    "axes[0].set_xlabel('True Affinity')\n",
    "axes[0].set_ylabel('Predicted Affinity')\n",
    "axes[0].set_title('Predictions vs Ground Truth')\n",
    "axes[0].legend()\n",
    "\n",
    "# Uncertainty distribution\n",
    "axes[1].hist(uncertainty, bins=20, alpha=0.7)\n",
    "axes[1].set_xlabel('Uncertainty')\n",
    "axes[1].set_ylabel('Frequency')\n",
    "axes[1].set_title('Prediction Uncertainty Distribution')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Training\n",
    "\n",
    "To train the model, use the provided training script:\n",
    "\n",
    "```bash\n",
    "python train.py --config config/default_config.yaml --dataset davis --split_type random\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7. Evaluation\n",
    "\n",
    "Evaluate trained models on cold-start scenarios:\n",
    "\n",
    "```bash\n",
    "python eval.py --checkpoint checkpoints/best_model.pt --dataset davis --evaluate_all_splits\n",
    "```"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
